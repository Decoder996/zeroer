# Beer 数据集测试结果分析

## 测试结果汇总

| 测试 | init_threshold | c_bay | 初始化正样本 | Precision | Recall | F1 |
|------|---------------|-------|-------------|-----------|--------|-----|
| 1 | 0.8 | 0.01 | 0.12% (553) | 0.03 | 0.79 | 0.06 |
| 2 | 0.8 | 0.02 | 0.12% (553) | 0.03 | 0.76 | 0.06 |
| 3 | 0.9 | 0.01 | **0.04% (202)** | 0.03 | 0.79 | 0.06 |
| 4 | 0.9 | 0.02 | **0.04% (202)** | 0.03 | 0.76 | 0.06 |
| 5 | 0.85 | 0.015 | 0.08% (348) | 0.03 | 0.76 | 0.06 |

## 关键发现

### ✅ 好消息：初始化大幅改善

- **原始问题**：初始化正样本 18.55% (85596)
- **优化后**：初始化正样本 0.04-0.12% (202-553)
- **改善幅度**：降低了 **99.8%**！

### ❌ 坏消息：最终结果没有改善

所有测试的最终结果几乎相同：
- **Precision**: 0.03（极低，假阳性太多）
- **Recall**: 0.76-0.79（较高）
- **F1**: 0.06（很低）

## 问题分析

### 核心问题

虽然初始化改善了，但 EM 算法在迭代过程中仍然产生了大量假阳性。这说明：

1. **特征质量问题**：可能特征无法有效区分正负样本
2. **极度不平衡**：68 个正样本 vs 46万+ 候选对，比例 < 0.015%
3. **EM 算法局限**：在极度不平衡的情况下，EM 可能无法收敛到好的解

### 为什么 Precision 这么低？

假设 Recall = 0.79，找到了 68 × 0.79 ≈ 54 个正样本。

如果 Precision = 0.03，意味着：
- 预测为正样本的总数 = 54 / 0.03 ≈ **1800 个**
- 假阳性 = 1800 - 54 = **1746 个**

这说明 EM 算法预测了约 1800 个正样本，但实际只有 54 个是真的。

## 下一步优化方向

### 方向 1: 更极端的参数（可能无效）

```bash
# 尝试更极端的阈值
python zeroer.py beer --init_threshold 0.95 --c_bay 0.03 --run_transitivity --LR_dup_free --n_jobs 4
```

但根据当前结果，这可能不会带来显著改善。

### 方向 2: 检查特征质量（推荐）

```bash
# 运行诊断脚本
python diagnose_zeroer.py beer
```

检查：
- 特征是否有区分度
- 是否有常数特征
- 特征分布是否合理

### 方向 3: 改进 Blocking（可能有效）

当前 blocking 使用 `overlap_size=2`，产生了 46万+ 候选对。可以考虑：
- 增加 `overlap_size` 到 3（更严格）
- 但可能漏掉更多正样本

### 方向 4: 后处理（实用方案）

由于 Precision 极低，可以考虑：
1. 使用更高的预测阈值（不是 0.5，而是 0.7 或 0.8）
2. 手动检查预测结果，找出高置信度的预测

### 方向 5: 接受现实（理性选择）

Beer 数据集极度不平衡（68/461335 = 0.015%），对于无监督方法来说，这可能是极限情况。论文中可能也没有报告 beer 的结果，或者结果也很低。

## 建议的下一步

1. **先运行诊断**：`python diagnose_zeroer.py beer`
2. **检查特征分布**：看看正负样本的特征是否有明显差异
3. **尝试更极端参数**：`--init_threshold 0.95 --c_bay 0.03`
4. **考虑改进 blocking**：如果可能，增加 `overlap_size` 到 3
5. **后处理预测结果**：使用更高的阈值过滤预测

## 结论

初始化问题已经解决（从 18.55% 降到 0.04%），但最终性能仍然很差。这可能是 beer 数据集本身的特性导致的，而不是参数问题。

