# Beer数据集优化最终报告

## 优化测试结果汇总

### 参数组合测试结果

| 测试 | init_threshold | c_bay | 初始化正样本 | Precision | Recall | F1 | 说明 |
|------|---------------|-------|-------------|-----------|--------|-----|------|
| **基准** | 0.8 | 0.015 | 3.79% (319) | 0.04 | 0.45 | 0.07 | 默认配置 |
| **测试1** | 0.9 | 0.02 | 1.61% (135) | 0.04 | 0.52 | **0.08** ✅ | 更严格初始化+强正则化 |
| **测试2** | 0.95 | 0.025 | 0.37% (31) | 0.04 | 0.52 | **0.08** ✅ | 最严格初始化+最强正则化 |
| **测试3** | 0.85 | 0.02 | 2.72% (229) | 0.04 | 0.52 | **0.08** ✅ | 平衡严格 |
| **测试4** | 0.7 | 0.01 | 7.91% (665) | 0.04 | 0.45 | 0.07 | 论文默认参数 |
| **测试5** | 0.6 | 0.005 | 12.71% (1069) | 0.04 | 0.43 | 0.07 | 宽松初始化+弱正则化 |
| **测试6** | 0.9 | 0.01 | 1.61% (135) | 0.04 | 0.45 | 0.07 | 严格初始化+论文默认正则化 |

### 最佳配置

**最佳结果: F1 = 0.08** (测试1, 2, 3)

**推荐配置:**
```bash
python zeroer.py beer --init_threshold 0.9 --c_bay 0.02 --run_transitivity --LR_dup_free --n_jobs 4
```

**关键参数:**
- `init_threshold=0.9`: 严格初始化，减少初始假阳性
- `c_bay=0.02`: 较强正则化，减少过拟合
- `--run_transitivity --LR_dup_free`: 使用传递性约束

## 优化效果分析

### ✅ 改善点

1. **F1提升**: 从0.07提升到0.08 (+14.3%)
2. **Recall提升**: 从0.45提升到0.52 (+15.6%)
3. **初始化改善**: 初始化正样本比例从3.79%降到0.37%-1.61%，更接近真实比例(0.77%)

### ⚠️ 仍存在的问题

1. **Precision极低**: 所有测试都是0.04，说明假阳性仍然很多
2. **F1仍然很低**: 0.08的F1分数对于实际应用来说仍然不够
3. **参数敏感性低**: 不同参数组合结果差异很小，说明参数调整空间有限

## 问题根源分析

### 1. 数据集特性

- **极度不平衡**: 65个正样本 vs 8,408个候选对 (0.77%)
- **Blocking后仍有大量候选对**: 虽然从46万降到8千，但正样本比例仍然很低
- **特征区分度可能不够**: 55个特征可能不足以在如此不平衡的情况下准确区分

### 2. 算法局限

- **EM算法在极度不平衡数据上的局限**: 即使初始化正确，EM算法仍可能产生大量假阳性
- **特征质量**: 可能某些特征对beer数据集不够有效
- **Blocking策略**: overlap_size=3可能仍然不够严格

## 进一步优化方向

### 方案1: 更严格的Blocking (推荐尝试)

当前使用`overlap_size=3`，可以尝试更严格：

```python
# 在blocking_functions.py中修改block_beer
C = ob.block_tables(A, B, 'Beer_Name', 'Beer_Name', word_level=True, overlap_size=4,
                    l_output_attrs=l_output_attrs, r_output_attrs=r_output_attrs,
                    show_progress=True, allow_missing=True)
```

**注意**: 这可能会漏掉更多正样本，但会显著减少候选对，可能提高Precision。

### 方案2: 多属性Blocking

尝试使用多个属性进行blocking：

```python
# 先按Beer_Name blocking，再按Brew_Factory_Name进一步过滤
C1 = ob.block_tables(A, B, 'Beer_Name', 'Beer_Name', word_level=True, overlap_size=2)
C2 = ob.block_candset(C1, 'Brew_Factory_Name', 'Brew_Factory_Name', word_level=True, overlap_size=2)
```

### 方案3: 特征工程优化

检查特征质量，可能需要：
- 添加领域特定的特征
- 过滤掉区分度低的特征
- 使用特征选择方法

### 方案4: 后处理优化

在预测后使用额外的规则过滤：
- 基于置信度阈值
- 基于多个特征的组合规则

### 方案5: 接受现实

Beer数据集可能确实不适合无监督方法，考虑：
- 使用半监督方法（少量标注数据）
- 使用主动学习
- 接受这是无监督方法的极限

## 当前最佳实践

### 运行命令

```bash
# 最佳配置
python zeroer.py beer --init_threshold 0.9 --c_bay 0.02 --run_transitivity --LR_dup_free --n_jobs 4
```

### 预期结果

- **F1**: 0.08
- **Precision**: 0.04
- **Recall**: 0.52

### 结果解释

- **找到约52%的正样本** (34/65个)
- **但假阳性很多** (Precision只有4%)
- **整体F1较低** (0.08)

## 结论

1. **参数优化已达到极限**: 通过参数调整，F1从0.07提升到0.08，但提升空间有限
2. **主要瓶颈**: Precision极低(0.04)，说明假阳性问题严重
3. **建议**: 
   - 如果必须使用无监督方法，当前配置已是最佳
   - 如果可能，考虑使用少量标注数据或改进blocking策略
   - 对于极度不平衡的数据集，无监督方法可能不是最佳选择

## 下一步行动

1. **尝试更严格的blocking** (overlap_size=4)
2. **分析预测结果**，找出假阳性的模式
3. **考虑使用半监督方法**，如果允许少量标注数据
4. **检查特征质量**，看是否需要特征工程

