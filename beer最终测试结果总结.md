# Beer 数据集最终测试结果总结

## 所有测试结果汇总

| 测试 | init_threshold | c_bay | 初始化正样本 | Precision | Recall | F1 |
|------|---------------|-------|-------------|-----------|--------|-----|
| 原始 | 0.5 | 0.01 | 18.55% (85596) | 0.03 | 0.79 | 0.06 |
| 1 | 0.8 | 0.01 | 0.12% (553) | 0.03 | 0.79 | 0.06 |
| 2 | 0.8 | 0.02 | 0.12% (553) | 0.03 | 0.76 | 0.06 |
| 3 | 0.9 | 0.01 | 0.04% (202) | 0.03 | 0.79 | 0.06 |
| 4 | 0.9 | 0.02 | 0.04% (202) | 0.03 | 0.76 | 0.06 |
| 5 | 0.85 | 0.015 | 0.08% (348) | 0.03 | 0.76 | 0.06 |
| **极端** | **0.95** | **0.03** | **0.01% (38)** | **0.03** | **0.74** | **0.06** |

## 关键发现

### ✅ 初始化问题已完全解决

- **原始问题**：初始化正样本 18.55% (85596)
- **极端参数**：初始化正样本 0.01% (38) - **完美！**
- **改善幅度**：降低了 **99.95%**！

### ❌ 最终性能完全未改善

**所有测试的最终结果几乎完全相同**：
- **Precision**: 0.03（极低，假阳性太多）
- **Recall**: 0.74-0.79（较高）
- **F1**: 0.06（很低）

即使初始化已经完美（0.01%，接近真实比例），EM 算法在迭代过程中仍然产生了大量假阳性。

## 问题根源分析

### 1. 数据集特性

- **极度不平衡**：68 正样本 / 461,335 候选对 = **0.015%**
- **候选对数量巨大**：46万+ 候选对
- **正样本比例极低**：这是无监督方法的极限情况

### 2. EM 算法的局限

即使初始化完美，EM 算法在极度不平衡的情况下：
- 容易陷入局部最优
- 难以区分相似但不匹配的样本
- 产生大量假阳性

### 3. 特征质量问题

可能的原因：
- 特征区分度不够
- 正负样本的特征分布重叠严重
- 55 个特征可能不足以在 46万+ 候选对中准确识别 68 个正样本

## 结论

### 参数优化已达到极限

- ✅ 初始化问题已完全解决（从 18.55% 降到 0.01%）
- ❌ 但最终性能无法通过参数调整改善
- 📊 所有参数组合的结果几乎相同

### 这可能是无监督方法的极限

Beer 数据集的极度不平衡特性（0.015%）使得无监督方法难以达到好的性能。这可能是：
1. **数据集本身的特性**：而不是参数问题
2. **无监督方法的极限**：对于如此不平衡的数据集，可能需要标注数据
3. **论文中可能也没有报告 beer 的结果**：或者结果也很低

## 最终建议

### 1. 接受当前结果（推荐）

当前结果（F1=0.06, Precision=0.03, Recall=0.74）可能是无监督方法在 beer 数据集上的极限。

### 2. 如果必须提高性能，考虑：

#### 方案 A: 改进 Blocking（可能有效但会漏样本）

修改 `blocking_functions.py` 中的 `block_beer` 函数：
- 将 `overlap_size=2` 改为 `overlap_size=3`
- 这会减少候选对数量，可能提高 Precision
- **但会漏掉一些正样本**（注释说会漏掉 3 个）

```python
# 修改后需要：
# 1. 删除旧特征文件：rm datasets/beer/candset_features_df.csv
# 2. 重新运行：python zeroer.py beer --init_threshold 0.9 --c_bay 0.02 --run_transitivity --LR_dup_free --n_jobs 4
```

#### 方案 B: 使用半监督方法

- 提供少量标注数据（例如 10-20 个正样本）
- 使用半监督学习方法
- 这可能需要修改代码或使用其他工具

#### 方案 C: 后处理预测结果

- 使用更高的预测阈值（例如 0.7 或 0.8）
- 手动检查高置信度的预测
- 这可以提高 Precision，但会降低 Recall

### 3. 最佳参数组合

基于所有测试，推荐使用：
```bash
python zeroer.py beer --init_threshold 0.9 --c_bay 0.02 --run_transitivity --LR_dup_free --n_jobs 4
```

**理由**：
- 初始化合理（0.04%，202 个正样本）
- 正则化适中（c_bay=0.02）
- 性能与其他组合相同，但参数更合理

## 总结

虽然我们成功解决了初始化问题（从 18.55% 降到 0.01%），但 beer 数据集的极度不平衡特性使得无监督方法难以达到更好的性能。这可能是数据集本身的特性，而不是参数或实现的问题。

**建议**：如果必须提高性能，考虑使用半监督方法或改进 blocking（但会漏掉一些正样本）。

